#spring.datasource.url=jdbc:mysql://localhost:3306/your_database_name   old local sql  url
spring.datasource.url=jdbc:mysql://34.93.252.28/UserDB
#spring.datasource.url=jdbc:mysql://35.200.231.100:3306/UserDB      last public Ip -it changes after deleting instance
# above url- 35.200.188.86:3306 is basically a public IP Address  under the instanceid created(now e-commerce-app)
# need to start virtual database -and server
spring.datasource.username= AdRahul
spring.datasource.password= Admin@123
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQLDialect
spring.application.name=Crud2


server.port=9090                  

# Logging level
logging.level.root=INFO
# Set to your base package
logging.level.crud2.Crud2=DEBUG 


# Log file output
# Log file will be created in /logs
logging.file.name=logs/myapp.log 

# Console log format
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# File log format
logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# application.properties
management.endpoints.web.exposure.include=*
management.endpoint.prometheus.enabled=true
management.metrics.export.prometheus.enabled=true

spring.security.user.name=admin
spring.security.user.password=admin


#  properties for Google cloud Dataflow

# GCP Project ID
gcp.project-id=e-commerce-app-rahul
gcp.bq.dataset=dataflowDemo
gcp.bq.table=Employee_Table
gcp.bucket.name=cllgstudataforbigquerydataflow
gcp.bucket.object=indian_employees_cleaned.csv
gcp.region=us-central1
gcp.temp.location=gs://cllgstudataforbigquerydataflow/tmp 